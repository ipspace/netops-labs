{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Building Network Automation Solutions Networking engineers attending the Building Network Automation Solutions online course had to solve several hands-on assignments, including: Build Your Own Network Automation Lab Easy Wins: Create Summary Reports Data Models: Create a Service Data Model Deploy Network Services From a Data Model Logging, Validation, and Testing I reviewed every single solution submitted by the course attendees. I can\u2019t do the same for everyone else, but you might still want to try to solve at least some of the challenges.","title":"Home"},{"location":"#building-network-automation-solutions","text":"Networking engineers attending the Building Network Automation Solutions online course had to solve several hands-on assignments, including: Build Your Own Network Automation Lab Easy Wins: Create Summary Reports Data Models: Create a Service Data Model Deploy Network Services From a Data Model Logging, Validation, and Testing I reviewed every single solution submitted by the course attendees. I can\u2019t do the same for everyone else, but you might still want to try to solve at least some of the challenges.","title":"Building Network Automation Solutions"},{"location":"EX-Build_Lab/","text":"Build Your Own Network Automation Lab In the first hands-on part of the Building Network Automation Solutions course, you\u2019ll build your lab and prepare an Ansible environment to control it. You\u2019ll also create a GitHub account and a local Git repository and publish a file to GitHub (you can also use any other Git-based public repository, for example, GitLab, BitBucket\u2026) You can work on your own or as a team with your colleagues or other course attendees (in which case, use our Slack team to find them). Selecting the Gear You can build your lab using physical gear or virtual routers, switches, firewalls, or load balancers. To make your job easier, I\u2019d suggest you select equipment you\u2019re familiar with that\u2019s supported by Ansible network modules . Some vendors offer free or evaluation versions of virtual network devices; others offer commercial environments: You can download Cumulus VX as a Vagrant box or Docker container. You can download Juniper vPTX with zero hassle, but you must build a Vagrant box from the disk image. Cisco CSR 1000V, Arista vEOS, and (probably) F5 require registration; Cisco VIRL (a commercial product) contains vASA, NX-OS, IOS-XR, IOS-XE, and IOSv. You\u2019ll also have to set up an environment running Ansible. You could install Ansible on your OSX or Linux workstation or run Ansible in a virtual machine or Docker container. You\u2019ll find more details in other documents mentioned in the lab exercise section . Building the Lab Your lab is ready when you\u2019re able to: SSH from your Ansible host to all network devices using usernames/passwords or SSH keys; Execute commands on your network devices with the Ansible raw module. Set up Git and GitHub After building the lab, it\u2019s time to set up Git and Github: Install Git on your workstation; Create a Github account; Create a new repository on GitHub; Create a local copy of that repository using this recipe (Github has pretty good step-by-step tutorials); If you\u2019re using Vagrant, create the local repository in a folder shared between your workstation and the virtual machine in which you\u2019re running Ansible. Publish a File on GitHub Finally, publish some content on Github: Create a text file describing your lab topology in your local Git repository. Use plain text (.txt) or Markdown. Tip I\u2019m using Visual Studio Code text editor. It has many add-ons, including syntax highlighting for YAML, Jinja2, and Markdown. Commit the changes and push them to Github. You\u2019ve completed the exercise when you can view the description of your lab topology with a web browser on github.com.","title":"Build Your Own Network Automation Lab"},{"location":"EX-Build_Lab/#build-your-own-network-automation-lab","text":"In the first hands-on part of the Building Network Automation Solutions course, you\u2019ll build your lab and prepare an Ansible environment to control it. You\u2019ll also create a GitHub account and a local Git repository and publish a file to GitHub (you can also use any other Git-based public repository, for example, GitLab, BitBucket\u2026) You can work on your own or as a team with your colleagues or other course attendees (in which case, use our Slack team to find them).","title":"Build Your Own Network Automation Lab"},{"location":"EX-Build_Lab/#selecting-the-gear","text":"You can build your lab using physical gear or virtual routers, switches, firewalls, or load balancers. To make your job easier, I\u2019d suggest you select equipment you\u2019re familiar with that\u2019s supported by Ansible network modules . Some vendors offer free or evaluation versions of virtual network devices; others offer commercial environments: You can download Cumulus VX as a Vagrant box or Docker container. You can download Juniper vPTX with zero hassle, but you must build a Vagrant box from the disk image. Cisco CSR 1000V, Arista vEOS, and (probably) F5 require registration; Cisco VIRL (a commercial product) contains vASA, NX-OS, IOS-XR, IOS-XE, and IOSv. You\u2019ll also have to set up an environment running Ansible. You could install Ansible on your OSX or Linux workstation or run Ansible in a virtual machine or Docker container. You\u2019ll find more details in other documents mentioned in the lab exercise section .","title":"Selecting the Gear"},{"location":"EX-Build_Lab/#building-the-lab","text":"Your lab is ready when you\u2019re able to: SSH from your Ansible host to all network devices using usernames/passwords or SSH keys; Execute commands on your network devices with the Ansible raw module.","title":"Building the Lab"},{"location":"EX-Build_Lab/#set-up-git-and-github","text":"After building the lab, it\u2019s time to set up Git and Github: Install Git on your workstation; Create a Github account; Create a new repository on GitHub; Create a local copy of that repository using this recipe (Github has pretty good step-by-step tutorials); If you\u2019re using Vagrant, create the local repository in a folder shared between your workstation and the virtual machine in which you\u2019re running Ansible.","title":"Set up Git and GitHub"},{"location":"EX-Build_Lab/#publish-a-file-on-github","text":"Finally, publish some content on Github: Create a text file describing your lab topology in your local Git repository. Use plain text (.txt) or Markdown. Tip I\u2019m using Visual Studio Code text editor. It has many add-ons, including syntax highlighting for YAML, Jinja2, and Markdown. Commit the changes and push them to Github. You\u2019ve completed the exercise when you can view the description of your lab topology with a web browser on github.com.","title":"Publish a File on GitHub"},{"location":"EX-Create_Service_Data_Model/","text":"Data Models: Create a Service Data Model In the hands-on part of the Data Models module, you\u2019ll build a comprehensive set of data models describing your devices, network infrastructure, and a sample service. To build the data model, start by listing the attributes you need to describe: Your nodes (device name, loopback IP address\u2026) Common network parameters (usernames, standard servers\u2026) Infrastructure (links, routing protocols\u2026) Service you want to model (customers, ports, port parameters, service parameters\u2026). You can build a data model for any network infrastructure and service you like. Here are a few examples: Internet access service; Managed IPsec VPN service; Managed firewall service (or firewall access lists); VLANs across a data center fabric (implemented with VXLAN, EVPN+VXLAN, TRILL, FabricPath\u2026) L2VPN or L3VPN service across an MPLS-enabled IP core. Select the Data Store(s) After grouping the attributes into these four categories, decide how to represent these parameters and where to store them. For example: Node-specific parameters will be stored in per-node YAML files in the host_vars directory. Alternatively, store all node-specific parameters in a single nodes.yml file. Common network parameters will be stored in the group_vars/all.yml file\u2026 or you could store them in the network.yml file and include variables from that file into your playbook. Infrastructure parameters will be stored in the fabric.yml file. The service model will be stored in the services.yml file. Abstract the Data Models Try to make the infrastructure and service data models as simple as possible and hide the underlying network complexity in the business logic (configuration templates). For example: Define links in your network, not individual ports on devices; Define IP prefixes on links (or use unnumbered links), not IP addresses on device ports; If you\u2019re running a single routing protocol in your network, don\u2019t specify routing protocol parameters in the data model unless absolutely necessary. Likewise, the service data model should be service-oriented rather than device-oriented. For example: Don\u2019t specify transport technologies (for example, VXLAN or DMVPN) in the service definition. Specify each service as a list of devices and ports on which that service should be configured, plus a few service-specific parameters (service name, VLAN ID, MPLS/VPN RT/RD\u2026). Sample Data Models You\u2019ll find sample infrastructure- and service data models in: Network Automation Data Model Optimization Abstract everything section of Network Automation Use Cases webinar; David Barroso\u2019s Network Tutorials and Ansible Demo repositories; DHCP Pools example (simple data store used to create local DHCP pools on Cisco IOS routers) OSPF Deployment - fabric data model with LLDP validation and fabric-to-node translation; MPLS Infrastructure - full-blown fabric- and services data models with OSPF, BGP, and MPLS/VPN deployment; VLAN service deployment - complete service deployment solution using a service data model to describe customer connectivity needs (= VLANs). Documentation Describe your data model (attributes, required values\u2026) in a text file, and include that text file in your GitHub repository. It doesn\u2019t matter how you describe your data model \u2013 the description must be concise enough to enable someone else to add new nodes, infrastructure components (links), or services. Sample data model descriptions are included with these examples: Manage DHCP pools Deploy IGP+BGP routing in a multi-AS MPLS/VPN network Validate the Data Model Build simple Jinja2 templates that will generate relevant parts of device configurations from your data model to verify that you\u2019ve included all pertinent parameters or that they\u2019re easy to derive from the data in the data model. For example, it\u2019s easy to generate node IP addresses if your data model includes infrastructure links defined like this \u2013 the left node gets the first IP address in the subnet, and the right node gets the second IP address. - left: E1 left_port: GigabitEthernet0/2 right: E2 right_port: GigabitEthernet0/2, subnet: 10.0.0.20/30 cost: 5 Sometimes, you might figure out that working with your data model in the configuration templates is hard. In that case, it might be better to insert an extra step and transform your service-oriented data model into a node-oriented one. More information You\u2019ll find several useful Jinja2 templates that work with abstracted infrastructure and services data models in David Barroso\u2019s Network Tutorials and Ansible Demo repositories; These documents will help you transform your data model: Data munging with Ansible and Jinja2 Playbooks in the MPLS Infrastucture and VLAN Service repositories (use this URL to get the simplest version of the VLAN services project that includes data model transformation) OSPF Deployment example","title":"Data Models: Create a Service Data Model"},{"location":"EX-Create_Service_Data_Model/#data-models-create-a-service-data-model","text":"In the hands-on part of the Data Models module, you\u2019ll build a comprehensive set of data models describing your devices, network infrastructure, and a sample service. To build the data model, start by listing the attributes you need to describe: Your nodes (device name, loopback IP address\u2026) Common network parameters (usernames, standard servers\u2026) Infrastructure (links, routing protocols\u2026) Service you want to model (customers, ports, port parameters, service parameters\u2026). You can build a data model for any network infrastructure and service you like. Here are a few examples: Internet access service; Managed IPsec VPN service; Managed firewall service (or firewall access lists); VLANs across a data center fabric (implemented with VXLAN, EVPN+VXLAN, TRILL, FabricPath\u2026) L2VPN or L3VPN service across an MPLS-enabled IP core.","title":"Data Models: Create a Service Data Model"},{"location":"EX-Create_Service_Data_Model/#select-the-data-stores","text":"After grouping the attributes into these four categories, decide how to represent these parameters and where to store them. For example: Node-specific parameters will be stored in per-node YAML files in the host_vars directory. Alternatively, store all node-specific parameters in a single nodes.yml file. Common network parameters will be stored in the group_vars/all.yml file\u2026 or you could store them in the network.yml file and include variables from that file into your playbook. Infrastructure parameters will be stored in the fabric.yml file. The service model will be stored in the services.yml file.","title":"Select the Data Store(s)"},{"location":"EX-Create_Service_Data_Model/#abstract-the-data-models","text":"Try to make the infrastructure and service data models as simple as possible and hide the underlying network complexity in the business logic (configuration templates). For example: Define links in your network, not individual ports on devices; Define IP prefixes on links (or use unnumbered links), not IP addresses on device ports; If you\u2019re running a single routing protocol in your network, don\u2019t specify routing protocol parameters in the data model unless absolutely necessary. Likewise, the service data model should be service-oriented rather than device-oriented. For example: Don\u2019t specify transport technologies (for example, VXLAN or DMVPN) in the service definition. Specify each service as a list of devices and ports on which that service should be configured, plus a few service-specific parameters (service name, VLAN ID, MPLS/VPN RT/RD\u2026).","title":"Abstract the Data Models"},{"location":"EX-Create_Service_Data_Model/#sample-data-models","text":"You\u2019ll find sample infrastructure- and service data models in: Network Automation Data Model Optimization Abstract everything section of Network Automation Use Cases webinar; David Barroso\u2019s Network Tutorials and Ansible Demo repositories; DHCP Pools example (simple data store used to create local DHCP pools on Cisco IOS routers) OSPF Deployment - fabric data model with LLDP validation and fabric-to-node translation; MPLS Infrastructure - full-blown fabric- and services data models with OSPF, BGP, and MPLS/VPN deployment; VLAN service deployment - complete service deployment solution using a service data model to describe customer connectivity needs (= VLANs).","title":"Sample Data Models"},{"location":"EX-Create_Service_Data_Model/#documentation","text":"Describe your data model (attributes, required values\u2026) in a text file, and include that text file in your GitHub repository. It doesn\u2019t matter how you describe your data model \u2013 the description must be concise enough to enable someone else to add new nodes, infrastructure components (links), or services. Sample data model descriptions are included with these examples: Manage DHCP pools Deploy IGP+BGP routing in a multi-AS MPLS/VPN network","title":"Documentation"},{"location":"EX-Create_Service_Data_Model/#validate-the-data-model","text":"Build simple Jinja2 templates that will generate relevant parts of device configurations from your data model to verify that you\u2019ve included all pertinent parameters or that they\u2019re easy to derive from the data in the data model. For example, it\u2019s easy to generate node IP addresses if your data model includes infrastructure links defined like this \u2013 the left node gets the first IP address in the subnet, and the right node gets the second IP address. - left: E1 left_port: GigabitEthernet0/2 right: E2 right_port: GigabitEthernet0/2, subnet: 10.0.0.20/30 cost: 5 Sometimes, you might figure out that working with your data model in the configuration templates is hard. In that case, it might be better to insert an extra step and transform your service-oriented data model into a node-oriented one.","title":"Validate the Data Model"},{"location":"EX-Create_Service_Data_Model/#more-information","text":"You\u2019ll find several useful Jinja2 templates that work with abstracted infrastructure and services data models in David Barroso\u2019s Network Tutorials and Ansible Demo repositories; These documents will help you transform your data model: Data munging with Ansible and Jinja2 Playbooks in the MPLS Infrastucture and VLAN Service repositories (use this URL to get the simplest version of the VLAN services project that includes data model transformation) OSPF Deployment example","title":"More information"},{"location":"EX-Create_Summary_Reports/","text":"Easy Wins: Create Summary Reports We\u2019ll keep the first encounter with Ansible and Ansible playbooks simple: you\u2019ll develop a playbook to collect information from your network and create a report based on the collected data. Regardless of what problem you decide to solve or how hard you want your task to be, you\u2019ll probably follow these steps: Define the problem (what do you want to report) Figure out how to get the information from the network devices Define the report format Create and test the playbook that collects the information and generates the report Write documentation Publish your solution to your Github account. Simple Reports Assuming you\u2019ve created the Ansible inventory file to solve the previous assignment , your playbook doesn\u2019t have to be more complex than this: Collect information from the host using SNMP (using snmp_facts ), REST API, or CLI commands returning JSON format (example: nxos_command with output set to json ), or device-specific facts ( ios_facts , nxos_facts , junos_facts \u2026). Using traditional CLI commands will make your job harder; Store the collected information in text files or create a summary report based on the information. Here are a few problems you could solve with this approach: Create a summary report listing device software version, uptime, memory utilization, interfaces, or IP addresses or subnets Collect MAC or ARP information from your devices and store it into text files (one per device) or use it to create a summary report. Create a hardware inventory report (assuming the devices you use in your lab return that information in an easy-to-use format). Verify that all devices in your network have DNS and NTP servers configured; More Advanced Reports Here are a few ideas if you\u2019re looking for a more challenging task: Parse CLI printouts in Ansible or Python filter, or use NAPALM or ntc-ansible modules to collect the information; Collect the list of IP addresses from devices, create a sorted list of subnets in your network, and list routers/interfaces/IP addresses in each subnet. Collect MAC and ARP information from your devices and create a summary report sorted by MAC addresses. Verify that all interfaces on which HSRP (or VRRP) is configured have an operational HSRP (or VRRP) neighbor. Data Manipulations and Interesting Templates If you want to practice your Jinja2 templating skills or try out data manipulation in Ansible, solve one of these challenges: Collect network topology using information from LLDP, OSPF, or BGP neighbors, and create a network diagram (hint: use GraphViz DOT or D2 file format); Collect device IP addresses and create DNS zone file and (advanced part) reverse DNS zone file. Supporting Materials Useful tools: Live Jinja2 parser/renderer is a great way to get started You\u2019ll probably find these videos from the Ansible for Networking Engineers materials useful: Baseline Ansible skills are covered in Using Ansible section (in particular the Introduction to Ansible and Ansible Playbooks videos). You might want to watch working with files video in Ansible Deeper Dive section. The Ansible Networking Modules \u2013 Executing Commands section describes Ansible modules you\u2019ll use to gather data and various ways of collecting information from networking devices. If you want to generate a summary report from a template, you\u2019ll have to be familiar with Jinja2 \u2013 watch the Creating Templates with Jinja2 section. Jinja2 whitespace control could get interestingly complicated - check out whitespace handing in Jinja2 .","title":"Easy Wins: Create Summary Reports"},{"location":"EX-Create_Summary_Reports/#easy-wins-create-summary-reports","text":"We\u2019ll keep the first encounter with Ansible and Ansible playbooks simple: you\u2019ll develop a playbook to collect information from your network and create a report based on the collected data. Regardless of what problem you decide to solve or how hard you want your task to be, you\u2019ll probably follow these steps: Define the problem (what do you want to report) Figure out how to get the information from the network devices Define the report format Create and test the playbook that collects the information and generates the report Write documentation Publish your solution to your Github account.","title":"Easy Wins: Create Summary Reports"},{"location":"EX-Create_Summary_Reports/#simple-reports","text":"Assuming you\u2019ve created the Ansible inventory file to solve the previous assignment , your playbook doesn\u2019t have to be more complex than this: Collect information from the host using SNMP (using snmp_facts ), REST API, or CLI commands returning JSON format (example: nxos_command with output set to json ), or device-specific facts ( ios_facts , nxos_facts , junos_facts \u2026). Using traditional CLI commands will make your job harder; Store the collected information in text files or create a summary report based on the information. Here are a few problems you could solve with this approach: Create a summary report listing device software version, uptime, memory utilization, interfaces, or IP addresses or subnets Collect MAC or ARP information from your devices and store it into text files (one per device) or use it to create a summary report. Create a hardware inventory report (assuming the devices you use in your lab return that information in an easy-to-use format). Verify that all devices in your network have DNS and NTP servers configured;","title":"Simple Reports"},{"location":"EX-Create_Summary_Reports/#more-advanced-reports","text":"Here are a few ideas if you\u2019re looking for a more challenging task: Parse CLI printouts in Ansible or Python filter, or use NAPALM or ntc-ansible modules to collect the information; Collect the list of IP addresses from devices, create a sorted list of subnets in your network, and list routers/interfaces/IP addresses in each subnet. Collect MAC and ARP information from your devices and create a summary report sorted by MAC addresses. Verify that all interfaces on which HSRP (or VRRP) is configured have an operational HSRP (or VRRP) neighbor.","title":"More Advanced Reports"},{"location":"EX-Create_Summary_Reports/#data-manipulations-and-interesting-templates","text":"If you want to practice your Jinja2 templating skills or try out data manipulation in Ansible, solve one of these challenges: Collect network topology using information from LLDP, OSPF, or BGP neighbors, and create a network diagram (hint: use GraphViz DOT or D2 file format); Collect device IP addresses and create DNS zone file and (advanced part) reverse DNS zone file.","title":"Data Manipulations and Interesting Templates"},{"location":"EX-Create_Summary_Reports/#supporting-materials","text":"Useful tools: Live Jinja2 parser/renderer is a great way to get started You\u2019ll probably find these videos from the Ansible for Networking Engineers materials useful: Baseline Ansible skills are covered in Using Ansible section (in particular the Introduction to Ansible and Ansible Playbooks videos). You might want to watch working with files video in Ansible Deeper Dive section. The Ansible Networking Modules \u2013 Executing Commands section describes Ansible modules you\u2019ll use to gather data and various ways of collecting information from networking devices. If you want to generate a summary report from a template, you\u2019ll have to be familiar with Jinja2 \u2013 watch the Creating Templates with Jinja2 section. Jinja2 whitespace control could get interestingly complicated - check out whitespace handing in Jinja2 .","title":"Supporting Materials"},{"location":"EX-Deploy_Network_Services/","text":"Deploy Network Services From a Data Model In this hands-on assignment, you\u2019ll create, deploy, and validate network device configurations using the infrastructure and services data model created in the previous hands-on assignment . You might decide to work on a single platform or implement a multi-platform or multi-vendor solution. Regardless of your end goal, start with a single-platform implementation and gradually extend it (which also means that you should start with a multi-vendor framework to avoid bloated code or extensive code refactoring when adding multi-platform support). If you work in a team, try splitting the multi-platform work across team members (each member working on a different platform) to get hands-on integration experience. Before You Start This hands-on assignment can turn into a massive project; you can easily spend a man-week or more to get it done. Hopefully, you\u2019ll eventually do it, but if you\u2019re short on time, trim it down to a manageable size. Regardless of where you decide to stop, write short documentation, commit the changes and push them to GitHub (or another public repository you\u2019re using), and submit the solution . The first step is the very minimum you should complete: create device configurations and deploy them on your lab devices. Ideally, you\u2019d also check the infrastructure deployment (LLDP neighbors, BGP neighbors, etc.). Those with more time should tackle the initial network services deployment task first and then proceed to the full-blown services project. Create Initial Device Configurations Using the data from node- and infrastructure data models, create initial device configurations using Jinja2 templates and deploy them on devices in your lab. If your devices support configuration, replace functionality, use that; otherwise, make sure the device configurations you create are idempotent (nothing gets deployed when you deploy the same configuration the second time). You can complete the job using the Ansible network device configuration management modules, NAPALM, or simple device commands (copy file to the device, replace configuration\u2026). Validate Infrastructure Configurations After deploying infrastructure-related device configuration, validate successful deployment by checking interface state, LLDP, OSPF, or BGP neighbors. Many devices can return the data you need for validation in a structured format that\u2019s easy to convert to Ansible facts; use NAPALM to simplify information gathering if your lab includes Cisco IOS devices. Deploy Initial Network Services Extend the initial solution to create network services configuration; Use configuration replace functionality to deploy the services; Validate correct deployment of network services. While the rest of the assignment is optional, I\u2019d highly recommend you complete it, as you\u2019ll often have to work in an ill-defined brownfield environment where the following approach is the only one with a reasonable chance of success. Incremental Services Deployment Modify the network services deployment solution to deploy services incrementally (by adding them to the device configurations instead of replacing whole configurations). Step 1: Start with a simple solution that generates target device configuration based on service definition, deploys the configuration, and validates correct service deployment. Step 2 : Add support for service removal \u2013 add configuration commands to remove any service marked with state: absent . Step 3 : Check the device state before configuring the services and reject the change if it overwrites an existing service. For example, reject adding a device into a VRF if it already belongs to another VRF (another customer). Step 4: Report extraneous services \u2013 list all target services (example: all VRFs) configured on a device, compare them to the expected list of configured services, and report any discrepancies. Step 5 : Automatic cleanup \u2013 automatically remove all unexpected services found on the network devices. Useful Links Managing network services configuration with Ansible Sample projects: Routing and MPLS infrastructure deployment VLAN services management (check out various branches to explore stages in the project development) OSPF deployment Network automation tutorial by David Barroso","title":"Deploy Network Services From a Data Model"},{"location":"EX-Deploy_Network_Services/#deploy-network-services-from-a-data-model","text":"In this hands-on assignment, you\u2019ll create, deploy, and validate network device configurations using the infrastructure and services data model created in the previous hands-on assignment . You might decide to work on a single platform or implement a multi-platform or multi-vendor solution. Regardless of your end goal, start with a single-platform implementation and gradually extend it (which also means that you should start with a multi-vendor framework to avoid bloated code or extensive code refactoring when adding multi-platform support). If you work in a team, try splitting the multi-platform work across team members (each member working on a different platform) to get hands-on integration experience.","title":"Deploy Network Services From a Data Model"},{"location":"EX-Deploy_Network_Services/#before-you-start","text":"This hands-on assignment can turn into a massive project; you can easily spend a man-week or more to get it done. Hopefully, you\u2019ll eventually do it, but if you\u2019re short on time, trim it down to a manageable size. Regardless of where you decide to stop, write short documentation, commit the changes and push them to GitHub (or another public repository you\u2019re using), and submit the solution . The first step is the very minimum you should complete: create device configurations and deploy them on your lab devices. Ideally, you\u2019d also check the infrastructure deployment (LLDP neighbors, BGP neighbors, etc.). Those with more time should tackle the initial network services deployment task first and then proceed to the full-blown services project.","title":"Before You Start"},{"location":"EX-Deploy_Network_Services/#create-initial-device-configurations","text":"Using the data from node- and infrastructure data models, create initial device configurations using Jinja2 templates and deploy them on devices in your lab. If your devices support configuration, replace functionality, use that; otherwise, make sure the device configurations you create are idempotent (nothing gets deployed when you deploy the same configuration the second time). You can complete the job using the Ansible network device configuration management modules, NAPALM, or simple device commands (copy file to the device, replace configuration\u2026).","title":"Create Initial Device Configurations"},{"location":"EX-Deploy_Network_Services/#validate-infrastructure-configurations","text":"After deploying infrastructure-related device configuration, validate successful deployment by checking interface state, LLDP, OSPF, or BGP neighbors. Many devices can return the data you need for validation in a structured format that\u2019s easy to convert to Ansible facts; use NAPALM to simplify information gathering if your lab includes Cisco IOS devices.","title":"Validate Infrastructure Configurations"},{"location":"EX-Deploy_Network_Services/#deploy-initial-network-services","text":"Extend the initial solution to create network services configuration; Use configuration replace functionality to deploy the services; Validate correct deployment of network services. While the rest of the assignment is optional, I\u2019d highly recommend you complete it, as you\u2019ll often have to work in an ill-defined brownfield environment where the following approach is the only one with a reasonable chance of success.","title":"Deploy Initial Network Services"},{"location":"EX-Deploy_Network_Services/#incremental-services-deployment","text":"Modify the network services deployment solution to deploy services incrementally (by adding them to the device configurations instead of replacing whole configurations). Step 1: Start with a simple solution that generates target device configuration based on service definition, deploys the configuration, and validates correct service deployment. Step 2 : Add support for service removal \u2013 add configuration commands to remove any service marked with state: absent . Step 3 : Check the device state before configuring the services and reject the change if it overwrites an existing service. For example, reject adding a device into a VRF if it already belongs to another VRF (another customer). Step 4: Report extraneous services \u2013 list all target services (example: all VRFs) configured on a device, compare them to the expected list of configured services, and report any discrepancies. Step 5 : Automatic cleanup \u2013 automatically remove all unexpected services found on the network devices.","title":"Incremental Services Deployment"},{"location":"EX-Deploy_Network_Services/#useful-links","text":"Managing network services configuration with Ansible Sample projects: Routing and MPLS infrastructure deployment VLAN services management (check out various branches to explore stages in the project development) OSPF deployment Network automation tutorial by David Barroso","title":"Useful Links"},{"location":"EX-Git_Recipe_Explained/","text":"Git Recipe Explained Git is a complex tool, so most novices try to cheat their way through with arcane recipes. As it\u2019s always better to understand what you\u2019re doing instead of a google-and-paste approach , let\u2019s analyze a pretty common one. Use it to describe your network automation lab . git init Git tracks changes you make in a distributed, eventually consistent database implemented with many small files in the .git directory. git init initializes that database within the .git subdirectory of the current directory. Use it in an empty directory you plan to use for your project. git remote add origin https://github.com/username/repository Git can synchronize the local database with multiple remote databases (repositories). Remote repositories are added with the git remote add command that takes at least two arguments : The nickname of the remote repository; The URI to access the remote repository. Warning The remote repository must exist before you run the git remote add command. For example, you must create a GitHub repository first, then do git remote add in an empty folder where you executed git init . Tip The URI git uses to access a remote repository can use non-HTTP(S) methods, such as SSH. All recipes call the remote repository origin (the default value), but you can give it any descriptive name, for example git remote add github url . git branch -M main In the old days, the initial Git branch was called the master branch. The Politically Correct movement forced numerous Git-based platforms to change the name of the initial branch to main . While I don\u2019t care how that branch is called, the git CLI tool does not necessarily share that sentiment, leaving you with an inconsistent branch naming scheme. If you need to rename the local branch, use the git branch -M new_name command. For example, the above command accommodates a remote Git platform that insists on naming its most initial branch main . echo \"# netops-labs\" >> README.md # or windows equivalent They wanted to say make the changes you want to make , but that would be too obvious. git add some_file.text # or 'git add .' for all git add adds a snapshot of the specified files to the staging area (prepares them for commit). If needed, remove the files from the staging area ( git status will tell you how) or replace them with newer versions with another git add command without modifying git repositories. Tip To see which files have been modified (or haven\u2019t been added to the git database yet), use the git status command. git commit -m 'a comment' git commit saves (commits) the changes from the staging area to the local repository. You can specify the commit message in the \u2013m parameter or use a text editor to write a longer message. git push -u origin main git push synchronizes the changes made in the local repository with a remote repository. Git keeps a mapping between local branches and remote branches so that you can use git push with no extra parameters to push changes to the remote repository. However, when you push changes for the first time, you have to specify the remote repository ( origin ) and remote branch ( main ), and tell Git that you want to create a new local-to-remote mapping with the -u or --set-upstream parameter.","title":"Git Recipe Explained"},{"location":"EX-Git_Recipe_Explained/#git-recipe-explained","text":"Git is a complex tool, so most novices try to cheat their way through with arcane recipes. As it\u2019s always better to understand what you\u2019re doing instead of a google-and-paste approach , let\u2019s analyze a pretty common one. Use it to describe your network automation lab . git init Git tracks changes you make in a distributed, eventually consistent database implemented with many small files in the .git directory. git init initializes that database within the .git subdirectory of the current directory. Use it in an empty directory you plan to use for your project. git remote add origin https://github.com/username/repository Git can synchronize the local database with multiple remote databases (repositories). Remote repositories are added with the git remote add command that takes at least two arguments : The nickname of the remote repository; The URI to access the remote repository. Warning The remote repository must exist before you run the git remote add command. For example, you must create a GitHub repository first, then do git remote add in an empty folder where you executed git init . Tip The URI git uses to access a remote repository can use non-HTTP(S) methods, such as SSH. All recipes call the remote repository origin (the default value), but you can give it any descriptive name, for example git remote add github url . git branch -M main In the old days, the initial Git branch was called the master branch. The Politically Correct movement forced numerous Git-based platforms to change the name of the initial branch to main . While I don\u2019t care how that branch is called, the git CLI tool does not necessarily share that sentiment, leaving you with an inconsistent branch naming scheme. If you need to rename the local branch, use the git branch -M new_name command. For example, the above command accommodates a remote Git platform that insists on naming its most initial branch main . echo \"# netops-labs\" >> README.md # or windows equivalent They wanted to say make the changes you want to make , but that would be too obvious. git add some_file.text # or 'git add .' for all git add adds a snapshot of the specified files to the staging area (prepares them for commit). If needed, remove the files from the staging area ( git status will tell you how) or replace them with newer versions with another git add command without modifying git repositories. Tip To see which files have been modified (or haven\u2019t been added to the git database yet), use the git status command. git commit -m 'a comment' git commit saves (commits) the changes from the staging area to the local repository. You can specify the commit message in the \u2013m parameter or use a text editor to write a longer message. git push -u origin main git push synchronizes the changes made in the local repository with a remote repository. Git keeps a mapping between local branches and remote branches so that you can use git push with no extra parameters to push changes to the remote repository. However, when you push changes for the first time, you have to specify the remote repository ( origin ) and remote branch ( main ), and tell Git that you want to create a new local-to-remote mapping with the -u or --set-upstream parameter.","title":"Git Recipe Explained"},{"location":"EX-Logging_Testing/","text":"Logging and Testing In this assignment, you\u2019ll add two testing features to the project you created in the previous assignment : Logging of configuration change results, Unit tests of a single component. Optional components: Automate unit testing; Validate input data. Logging Add tasks in your playbooks that will log results returned by every interaction with the networking devices (for example, results returned by every ios_config or ios_command task). Make logging conditional \u2013 the results should be logged only when an Ansible variable is set. Optional: Assign a unique ID (example: timestamp) to every playbook run and store logging data for each playbook run in a dedicated subdirectory. This will allow you to examine potential playbook failures even when someone has rerun the playbooks. Unit Testing Choose a single component of your project (generating device configurations, transforming the data model\u2026). Create numerous test scenarios with valid and invalid input data. Tip The easiest way to create test scenarios for a component is to store Ansible facts into a YAML or JSON file just before that component is executed in your playbook and then create multiple variants of the input data. Create a test harness for your component. It can be as easy as \u201cread variables for the test scenario, execute the component, save the results.\u201d Test your component and verify it returns the expected results under all input conditions. Automate Unit Testing Create expected results for all unit tests you created in the previous step. Expected results might be a dump of Ansible variables or a text file with well-known content (for example, device configuration) Create a playbook (or a bash script) that will automatically execute all unit tests for your component and compare actual results with expected results Hints: Use yamllint to verify your YAML data is well-formatted Use diff called with shell module to compare text files Use jq to compare JSON documents . Validate Input Data Use test-driven development approach in this step: Identify all potential errors in your input data. Create unit tests for the data validation component \u2013 variants of input data with one or more errors. Start by introducing a single error in every unit test. Create a test harness for the data validation component and a playbook or bash script that automates the unit tests. Tip My test harness is a full-blown Ansible playbook, and as I couldn\u2019t get it to work from within another Ansible playbook (using the shell module), I created a bash script to automate the unit tests. After creating the environment: Add code that will detect one of the potential input errors. Execute unit tests to verify that your code detects the error. Repeat as long as feasible. Some errors (for example, duplicate composite keys) are notoriously hard to detect without writing a Python plug-in. Useful Links Explore the Logging and Pre-deploy check branches of the VLAN services project .","title":"Logging and Testing"},{"location":"EX-Logging_Testing/#logging-and-testing","text":"In this assignment, you\u2019ll add two testing features to the project you created in the previous assignment : Logging of configuration change results, Unit tests of a single component. Optional components: Automate unit testing; Validate input data.","title":"Logging and Testing"},{"location":"EX-Logging_Testing/#logging","text":"Add tasks in your playbooks that will log results returned by every interaction with the networking devices (for example, results returned by every ios_config or ios_command task). Make logging conditional \u2013 the results should be logged only when an Ansible variable is set. Optional: Assign a unique ID (example: timestamp) to every playbook run and store logging data for each playbook run in a dedicated subdirectory. This will allow you to examine potential playbook failures even when someone has rerun the playbooks.","title":"Logging"},{"location":"EX-Logging_Testing/#unit-testing","text":"Choose a single component of your project (generating device configurations, transforming the data model\u2026). Create numerous test scenarios with valid and invalid input data. Tip The easiest way to create test scenarios for a component is to store Ansible facts into a YAML or JSON file just before that component is executed in your playbook and then create multiple variants of the input data. Create a test harness for your component. It can be as easy as \u201cread variables for the test scenario, execute the component, save the results.\u201d Test your component and verify it returns the expected results under all input conditions.","title":"Unit Testing"},{"location":"EX-Logging_Testing/#automate-unit-testing","text":"Create expected results for all unit tests you created in the previous step. Expected results might be a dump of Ansible variables or a text file with well-known content (for example, device configuration) Create a playbook (or a bash script) that will automatically execute all unit tests for your component and compare actual results with expected results Hints: Use yamllint to verify your YAML data is well-formatted Use diff called with shell module to compare text files Use jq to compare JSON documents .","title":"Automate Unit Testing"},{"location":"EX-Logging_Testing/#validate-input-data","text":"Use test-driven development approach in this step: Identify all potential errors in your input data. Create unit tests for the data validation component \u2013 variants of input data with one or more errors. Start by introducing a single error in every unit test. Create a test harness for the data validation component and a playbook or bash script that automates the unit tests. Tip My test harness is a full-blown Ansible playbook, and as I couldn\u2019t get it to work from within another Ansible playbook (using the shell module), I created a bash script to automate the unit tests. After creating the environment: Add code that will detect one of the potential input errors. Execute unit tests to verify that your code detects the error. Repeat as long as feasible. Some errors (for example, duplicate composite keys) are notoriously hard to detect without writing a Python plug-in.","title":"Validate Input Data"},{"location":"EX-Logging_Testing/#useful-links","text":"Explore the Logging and Pre-deploy check branches of the VLAN services project .","title":"Useful Links"}]}